###

code: hello.c

> 信息就是位 + 上下文

hello 程序的生命周期是从一个 **源程序（或者说源文件）** 开始的，即 hello.c。源程序实际上就是一个由
值 0 和 1 组成的位（又称为比特）序列，8 个位被组织成一组，称为 **字节**。每个字节表示程序中的某些文
本字符。

大部分现代计算机系统都使用 ASCII 标准来表示文本字符，这种方式实际上就是用一个唯一的单字节大小的整数
值来表示每个字符。hello.c 程序是以字节序列的方式储存在文件中的。每个字节都有一个整数值，对应于某些字
符。像 hello.c 这样只由 ASCII 字符构成的文件称为 **文本文件**，所有其他文件都称为 **二进制文件**。

hello.c 的表示方法说明了一个基本思想：系统中所有的信息，都是由一串比特表示的。区分不同数据对象的唯一
方法是读到这些数据对象时的上下文。比如，在不同的上下文中，一个同样的字节序列可能表示一个整数、浮点数、
字符串或者机器指令。


> 程序被其他程序翻译成不同的格式

hello 程序的生命周期是从一个高级 C 语言程序开始的，因为这种形式能够被人读懂。然而，为了在系统上运行
hello.c 程序，每条 C 语句都必须被其他程序转化为一系列的低级 **机器语言** 指令。然后这些指令按照一
种称为 **可执行目标程序** 的格式打好包，并以二进制磁盘文件的形式存放起来。目标程序也称为 **可执行目
标文件**。

在 Unix 系统上，从源文件到目标文件的转化是由 **编译器驱动程序** 完成的：

```linux> gcc -o hello hello.c```

在这里，GCC 编译器驱动程序读取源程序文件 hello.c，并把它翻译成一个可执行目标文件 hello。这个翻译过
程可分为四个阶段完成。执行这四个阶段的程序（预处理器、编译器、汇编器和链接器）一起构成了 **编译系统(
compilation system)**。

编译系统：

```
hello.c(源程序[文本]) --预处理器(cpp)--> hello.i(修改了源程序[文本]) --编译器(ccl)--> hello.s(汇编程序[文本])  

--汇编器(as)--> hello.o(可重定位目标程序(二进制)[+ printf.o] --链接器(ld)--> hello(可执行目标程序[二进制])
```

* 预处理阶段。预处理器(cpp)根据以字符`#`开头的命令，修改原始的 C 程序。
* 编译阶段。编译器(ccl)将文本文件 hello.i 翻译成文本文件 hello.s，它包含一个汇编语言程序，该程序包
  含函数 main 的含义，如下所示：
    ```
    main:
        subq    $8, %rsp
        mov1    $.LCO, %edi
        call    puts
        mov1    $0, %eax
        addq    $i, %rsp
        ret
    ```  
  定义中 2～7 行的每条语句都以一种文本格式描述了一条低级机器语言指令。汇编语言非常有用，因为它为不同
  高级语言的不同编译器提供了通用的输出语言。例如，C 编译器和 Fortran 编译器产生的输出文件用的都是一
  样的汇编语言。 
* 汇编阶段。接下来，汇编器(as)将 hello.s 翻译成机器语言指令，把这些指令打包成一种叫做 **可重定位目标
  程序(relocatable object program)** 的格式，并将结果保存在目标文件 hello.o 中。hello.o 文件是一
  个二进制文件，它包含的 17 个字节是函数 main 的指令编码。如果在文本编辑器打开 hello.o 文件，将看到一
  堆乱码。
* 链接阶段。请注意，hello 程序调用了 printf 函数，它是每个 C 编译器都提供的标准 C 库中的一个函数。
  printf 函数存在于一个名为 printf.o 的单独的预编译好了的目标文件中，而这个文件必须以某种方式合并到 
  hello.c 程序中。链接器(ld)就负责处理这种合并。结果就得到 hello 文件，它是一个 **可执行目标文件** 
  (或者简称为 **可执行文件**)，可以被加载到内存中，由系统执行。


> 了解编译系统如何工作是大有益处的

对于像 hello.c 这样简单的程序，我们可以依靠编译系统生成正确有效的机器代码。但是有一些重要的原因促使程序
员必须知道编译系统是如何工作的。

* `优化程序性能`。为了在 C 程序中做出好的编码选择，确实需要了解一些机器代码以及编译器不同的 C 语句转化为
  机器代码的方式。比如，一个 switch 语句是否总是比一系列的 if-else 语句高效得多？一个函数调用的开销有
  多大？while 循环比 for 循环更有效吗？指针引用比数组索引更有效吗？为什么循环求和的结果放到一个本地变
  量中，会比将其放到一个通过引用传递过来的参数中，运行起来快得多吗？为什么我们只是简单地重新排列一下算术
  表达式中的括号就能让函数运行得更快？
* `理解链接时出现的错误`。一些最令人困扰的程序错误往往都与链接器操作有关。比如，链接器报告无法解析一下引用，
  这是什么意思？静态变量和全局变量的区别是什么？如果在不同的 C 文件中定义了名字相同的两个全局变量会发生
  什么？静态库和动态库的区别是什么？我们在命令行上排列库的顺序有什么影响？最严重的是，为什么有些链接错误
  直到运行时才会出现？
* `避免安全漏洞`。多年来，缓冲区溢出错误是造成大多数网络和 Internet 服务器上安全漏洞的主要原因。存在这些错
  误是因为很少有程序员能够理解需要限制从不受信任的源接收数据的数量和格式。学习安全编程的第一步就是理解数据
  和控制信息存储在程序栈上的方式会引起的后果。


> 处理器读取并解释储存在内存中的指令

hello.c 源程序已经被编译系统翻译成了可执行目标文件 hello，要想在 Unix 系统上运行该可执行文件，将它的文件名
输入到 shell 中：

```
linux> ./hello
hello, world
linux>
```

>> 系统的硬件组成

为了理解运行 hello 程序时发生了什么，需要了解一个典型系统的硬件组织。以下以近期 Inter 系统产品族的模型为例。
所有其他系统也有相同的外观和特性。

* 总线。贯穿整个系统的是一组电子管道，称作`总线`。它携带信息字节并负责在各个部件间传递。通常总线被设计成传
  送定长的字节块，也就是`字(word)`。字中的字节数（即字长）是一个基本的系统参数，各个系统中都不尽相同。现在
  大多数机器字长要么是 4 个字节（32位），要么是 8 个字节（64位）。
* I/O 设备。I/O（输入/输出）设备是系统与外部世界的联系通道。示例系统包括四个 I/O 设备：作为用户输入的键盘
  和鼠标，作为用户输出的显示器，以及用于长期存储数据和程序的磁盘驱动器（简单地说就是磁盘）。最开始，可执行
  程序 hello 就存放在磁盘上。
  
  每个 I/O 设备都通过一个`控制器`或`适配器`与 I/O 总线相连。控制器和适配器之间的区别主要在于它们的封装方式。
  控制器是 I/O 设备本身或者系统的主印制电路板（通常称作`主板`）上的芯片组。而适配器则是一块插在主板插槽上的
  卡。无论如何，它们的功能都是在 I/O 总线和 I/O 设备之间传递信息。
* 主存。`主存`是一个临时存储设备，在处理器执行程序时，用来存放程序和程序处理的数据。从物理上来说，主存是一
  组`动态随机存取存储器(DRAM)`芯片组成的。从逻辑上来说，存储器是一个线性的字节数组，每个字节都有其唯一的地
  址（数组索引），这些地址是从零开始的。一般来说，组成程序的每条机器指令都由不同数量的字节构成。
* 处理器。`中央处理单元(CPU)`，简称`处理器`。是解释（或执行）存储在主存中指令的引擎。处理器的核心是一个大小
  为一个字的存储设备（或寄存器），称为`程序计数器(PC)`。在任何时间，PC 都指向主存中的某条机器语言指令（即含
  有该条指令的地址）。

  从系统通电开始，直到系统断电，处理器一直在不断地执行程序计数器指向的指令，再更新程序计数器，使其指向下一
  条指令，再更新程序计数器，使其指向下一条指令。处理器看上去是按照一个非常简单的指令执行模型来操作的，这个
  模型是由指令集架构决定的。在这个模型中，指令按照严格的顺序执行，而执行一条指令包含执行一系列的步骤。处理
  器从程序计数器指向的内存处读取指令，解释指令中的位，执行该指令指示的简单操作，然后更新 PC，使其指向下一条
  指令，而这条指令并不一定和在内存中刚刚执行的指令相邻。

  这样的简单操作并不多，它们围绕着主存、`寄存器文件(register file)`和`算术/逻辑单元(ALU)`进行。寄存器文件是
  一个小的存储设备，由一些单个字长的寄存器组成，每个寄存器都有唯一的名字。ALU 计算新的数据和地址值。下面是一
  些简单的例子，CPU 在指令的的要求下可能会执行这些操作：
    * 加载：从主存复制一个字节或者一个字到寄存器，以覆盖寄存器原来的内容。
	* 存储：从寄存器复制一个字节或者一个字到主存的某个位置，以覆盖这个位置上原来的内容。
	* 操作：把两个寄存器的内容复制到 ALU，ALU 对这两个字做算术运算，并将结果存放到一个寄存器中，以覆盖该寄存
	  器中原来的内容。
	* 跳转：从指令本身中抽取一个字，并将这个字复制到程序计数器(PC)中，以覆盖 PC 中原来的值。

>> 运行 hello 程序

初始时，shell 程序执行它的指令，等待我们输入一个命令。当我们在键盘上输入字符串"./hello"后，shell 程序将它符逐
一读入寄存器，再把它存放到内存中。当在键盘上敲回车键时，shell 就知道结束了命令的输入。然后 shell 执行一系列指
令来加载可执行的 hello 文件，这些指令将 hello 目标文件中的代码和数据从磁盘复制到主存。数据包括最终会被输出的字
符串"hello, world\n"。

利用 **直接存储器存取(DMA)** 技术，数据可以不通过处理器而直接从磁盘到达主存。

一旦目标文件 hello 中的代码和数据被加载到主存，处理器就开始执行 hello 程序的 main 程序中的机器语言指令。这些指
令将"hello, world\n"字符串中的字节从主存复制到寄存器文件，再从寄存器文件中复制到显示设备，最终显示在屏幕上。


> 高速缓存至关重要

这个简单的示例揭示了一个重要的问题，即系统花费了大量的时间把信息从一个地方挪到另一个地方。hello 程序的机器指令
最初是存放在磁盘上，当程序加载时，它们被复制到主存；当处理器运行程序时，指令又从主存复制到处理器。相似地，数据
串"hello, world\n"开始时磁盘上，然后被复制到主存，最后从主存上复制到显示设备。从程序员的角度来看，这些复制就是
开销，减慢了程序"真正"的工作。因此，系统设计者的一个主要目标就是使这些复制操作尽可能快地完成。

根据机械原理，较大的存储设备要比较小的存储设备运行得慢，而快速设备的造价远高于同类的低速设备。比如说，一个典型
系统上的磁盘驱动器可能比主存大 1000 倍，但是对于处理器而言，从磁盘驱动器上读取一个字的时间开销要比从主存中读取
的开销大 1000 万倍。

类似地，一个典型的寄存器文件只存储几百字节的信息，而主存里可存放几十亿字节。然而，处理器从寄存器文件读数据比从
主存中读取几乎要快 100 倍。更麻烦的是，随着这些年半导体技术的进步，这种处理器与主存之间的差距还在持续增大。加
快处理器的运行速度比加快主存的运行速度要容易和便宜得多。

针对这种处理器与主存之间的差异，系统设计者采用更小更快的存储设备，称为 **高速缓存存储器**(cache memory，简称为 
cache 或高速缓存)，作为暂时的集结区域，存放处理器近期可能会需要的信息。位于处理器芯片上的 L1 高速缓存的容量可以
达到数万字节，访问速度几乎和访问寄存器文件一样快。进程访问 L2 高速缓存的时间要比访问 L1 高速缓存的时间长 5 倍，
但仍比访问主存时间快 5～10 倍。L1 和 L2 高速缓存是用一种叫做 **静态随机访问存储器(SRAM)** 的硬件技术实现的。比
较新的、处理能力更强大的系统甚至有三级高速缓存：L1、L2 和 L3。通过让高速缓存里存放可能经常访问的数据，大部分的
内存操作都能在快速的高速缓存中完成。


> 存储设备形成层次结构

在处理器和一个较大较慢的设备（例如内存）之间插入一个更小更快的存储设备（例如高速缓存）的想法已经成为一个普遍的
观念。实际上，每个计算机系统中的存储设备都被组织成了一个 **存储器层次结构**。在这个层次结构中，从上至下，设备的
访问速度越来越慢、容量越来越大，并且每字节的造价也越来越便宜。寄存器文件在层次结构中位于最顶部，也就是第 0 级或
者记为 L0。然后是三层高速缓存 L1 到 L3，主存在第 4 层，以此类推。

```
L0: 寄存器
L1：L1 高速缓存(SRAM)
L2：L2 高速缓存(SRAM)
L3：L3 高速缓存(SRAM)
L4：L4 主存(DRAM)
L5：L5 本地二级存储（本地磁盘）
L6：L6 远程二级存储（分布式文件系统，Web 服务器）
```

存储器层次结构的主要思想是上一层的存储器作为低一层存储器的高速缓存。寄存器文件就是 L1 的高速缓存，以此类推。
正如可以运用不同的高速缓存的知识来提高程序性能一样，程序员同样可以利用对整个存储器层次结构的理解来提高程序性能。


> 操作系统管理硬件

回到 hello 程序的例子。当 shell 加载和运行 hello 程序时，以及 hello 程序输出自己的消息时，shell 和 hello 程序都
没有直接访问键盘、显示器、磁盘或者主存。取而代之，它们依靠操作系统提供的服务。可以把操作系统看成是应用程序和硬件
之间插入的一层软件，所有应用程序对硬件的操作尝试都必须通过操作系统。

操作系统有两个基本功能：
1. 防止硬件被失控的应用程序滥用；
2. 向应用程序提供简单一致的机制来控制复杂而又通常大不相同的低级硬件设备。操作系统通过几个基本的抽象概念（进程、
   虚拟内存和文件）来实现这两个功能。

文件是对 I/O 设备的抽象表示，虚拟内存是对主存和磁盘 I/O 设备的抽象表示，进程则是对处理器、主存和 I/O 设备的抽象
表示。

>> 进程

像 hello 这样的程序在现代系统上运行时，操作系统会提供一种假象，就好像系统上只有这个程序在运行。程序看上去是独占
地使用处理器、主存和 I/O 设备。处理器看上去就像在不间断地一条接一条地执行程序中的指令，即该程序的代码和数据是系
统内存中唯一的对象。这些假象是通过进程的概念来实现的，进程是计算机科学中最重要和最成功的概念之一。

**进程** 是操作系统对一个正在运行的程序的一种抽象。在一个系统上可以同时运行多个进程，而每个进程都好像在独占地使
用硬件。而 **并发运行**，则是说一个进程的指令和另一个进程的指令是交错执行的。在大多数系统中，需要运行的进程数是
多于可以运行它们的 CPU 个数的。传统系统在一个时刻只能执行一个程序，而先进的多核处理器同时能够执行多个程序。无论
是在单核还是多核系统中，一个 CPU 看上去都像是在并发地执行多个进程，这是通过处理器在进程间切换来实现的。操作系统
实现这种交错执行的机制称为 **上下文切换**。为了简化讨论，现只考虑包含一个 CPU 的单处理器系统的情况。

操作系统保持跟踪进程运行所需的所有状态信息。这种状态，也就是 **上下文**。在任何一个时刻，单处理器系统都只能执行
一个进程的代码。当操作系统决定要把控制权从当前进程转移到某个新进程时，就会进行 **上下文切换**，即保存当前进程的
上下文、恢复新进程的上下文，然后把控制权传递到新进程。新进程就会从它上次停止的地方开始。

从一个进程到另一个进程的转换是由操作系统 **内核(kernel)** 管理的。内核是操作系统代码常驻主存的部分。当应用程序需
要操作系统的某些操作时，比如读写文件，它就执行一条特殊的 **系统调用(system call)** 指令，将控制权传递给内核。然后
内核执行被请求的操作并返回应用程序。注意，内核不是一个独立的进程。相反，它是系统管理全部进程所用代码和数据结构的
集合。

>> 线程

尽管通常我们认为一个进程只有单一的控制流，但是在现代系统中，一个进程实际上可以由多个称为 **线程** 的执行单元组成，
每个线程都运行在进程的上下文中，并共享同样的代码和全部数据。由于网络服务器中对并行处理的需求，线程成为越来越重要
的编程模型，因为多线程之间比多进程之间更容易共享数据，也因为线程一般来说都比进程更高效。当有多处理器可用的时候，
多线程也是一种使得程序可以运行得更快的方法。

>> 虚拟内存

**虚拟内存** 是一个抽象概念，它为每个进程提供了一个假象，即每个进程都在独占地使用主存。每个进程看到的内存都是一致
的，称为 **虚拟地址空间**。以下是 Linux 进程的虚拟地址空间，地址空间最上面的区域是保留给操作系统中的代码和数据的，
这对所有进程来说都是一样。地址空间的询问区域存放用户进程定义的代码和数据。注意，图中的地址是从下往上增大的。

```
内核虚拟内存（用户代码不可见的内存）
用户栈（运行时创建的）
共享库的内存映射区域（printf 函数）
运行时堆（在运行时由 malloc 创建的）
读/写数据（从 hello 可执行文件加载进来的）
只读的代码和数据（从 hello 可执行文件加载进来的）
程序开始
0
```

每个进程看到的虚拟地址空间由大量准确定义的区构成，每个区都有专门的功能。先简单了解每一个区，从最低的地址开始。

* 程序代码和数据。对所有进程来说，代码是从同一固定位置开始，紧接着的是和 C 全局变量相对应的数据位置。
* 堆。代码和数据区后紧随着的是运行时堆。代码和数据区在进程一开始进行时就被指定了大小，与此不同，当调用像 malloc
  和 free 这样的 C 标准库函数时，堆可以在运行时动态地扩展和收缩。
* 共享库。大约在地址空间的中间部分是一块用来存放像 C 标准库和数学库这样的共享库的代码和数据的区域。
* 栈。位于用户虚拟地址空间顶部的是用户栈，编译器用它来实现函数调用。和堆一样，用户栈在程序执行期间可以动态地
  扩展和收缩。特别地，每次调用一个函数时，栈就会增长；从一个函数返回时，栈就会收缩。
* 内核虚拟内存。地址空间顶部的区域是为内核保留的。不允许应用程序读写这个区域的内容或者直接调用内核代码定义的函数

>> 文件

**文件** 就是字节序列，仅此而已。每个 I/O 设备，包括磁盘、键盘、显示器，甚至网络，都可以看成是文件。系统中的所有
输入输出都是通过使用一小组称为 Unix I/O 的系统函数调用读写文件来实现的。

文件这个简单而精致的概念是非常强大的，因为它向应用程序提供了一个统一的视图，来看待系统中可能含有的所有各式各样的 
I/O 设备。


> 系统之间利用网络通信

从一个单独的系统来看，网络可视为一个 I/O 设备。当系统从主存复制一串字节到网络适配器时，数据流经过网络到达另一台机器，
而不是比如说到达本地磁盘驱动器。相似地，系统可以读取从其他机器发送来的数据，并把数据复制到自己的主存。

随着 Internet 这样的全球网络的出现，从一台主机复制信息到另外一台主机已经成为计算机系统最重要的用途之一。比如，像电子
邮件、即时通信、万维网、FTP 和 telnet 这样的应用都是基于网络复制信息的功能。

回到 hello 示例，可以用 telnet 应用在远程主机上运行 hello 程序，假设用本地主机上的 telnet 客户端连接远程主机上的
telnet 服务器。在我们登录到远程主机并运行 shell 后，远端的 shell 就在等待接收输入命令。

当在 telnet 客户端键入"hello"字符串并敲下回车键后，客户端软件就会将这个字符串发送到 telnet 服务器。telnet 服务器
从网络上接收到这个字符串后，会把它传递给远端 shell 程序。接下来，远端 shell 运行 hello 程序，并将输出行返回给 
telnet 服务器。最后，telnet 服务器通过网络把输出串转发给 telnet 客户端，客户端就将输出串输出到我们的本地终端上。


> 重要主题

系统不仅仅只是硬件。系统是硬件和系统软件互相交织的集合体，它们必须共同协作以达到运行应用程序的最终目的。作为本章的结束，
在此强调几个贯穿计算机所有方面的重要概念

>> Amdahl 定律

Amdahl定律的主要思想是，当我们对系统的某个部分加速时，其对系统整体性能的影响取决于该部分的重要性和加速程度。

>> 并发和并行

数字计算机的整个历史中，有两个需求是驱动进步的持续动力：一个是我们想要计算机做得更多，另一个是我们想要计算机运行得更快。
当处理器能够同时做更多的事情时，这两个因素都会改进。

**并发(concurrency)** 是一个通用的概念，指一个同时具有多个活动的系统；
**并行(parallelism)** 指的是用并发来使一个系统运行得更快；

以下按照系统层次结构中由高到低的顺序重点强调三个层次：

>>> 线程级并发

构建在进程这个抽象之上，我们能够设计出同时有多个程序执行的系统，这就导致了并发。使用线程，我们甚至能够在一个进程中执行多个
控制流。传统意义上的并发模拟出来的，是通过使一台计算机在它正在执行的进程间快速切换来实现的。在以前，即使处理器必须在多个任
务间切换，大多数实际的计算也都是由一个处理器来完成的。这种配置称为 **单处理器系统**。

当构建一个由单操作系统内核控制的多处理器组成的系统时，就得到一个 **多处理器系统**。到现在，随着 **多核** 处理器和 
**超线程(hyperthreading)** 的出现，这种系统已经很常见了。

多核处理器是将多个 CPU（称为"核"）集成到一个集成电路芯片上。